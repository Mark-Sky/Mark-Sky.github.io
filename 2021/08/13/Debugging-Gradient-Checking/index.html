<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="John Doe">







<title>Debugging Gradient Checking | Hexo</title>



    <link rel="icon" href="/favicon.ico">



<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@300;400;500;700&display=swap');
</style>



    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    




    <!-- scripts list from _config.yml -->
    
    <script src="/js/frame.js"></script>
    




    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>




  <!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>
  <body>
    <div class="mask-border">
    </div>

    <div class="wrapper">

      <div class="header">
  <div class="flex-container">
    <div class="header-inner">
      <div class="site-brand-container">
        <a href="/">Frame.</a>
      </div>
      <div id="menu-btn" class="menu-btn" onclick="toggleMenu()">
        Menu
      </div>
      <nav class="site-nav">
        <ul class="menu-list">
          
            
              <li class="menu-item">
                <a href="/">Home</a>
              </li> 
                   
          
            
              <li class="menu-item">
                <a href="/archives/">Archive</a>
              </li> 
                   
          
            
              <li class="menu-item">
                <a href="/categories/gallery/">Gallery</a>
              </li> 
                   
          
        </ul>
      </nav>
    </div>
  </div>
</div>


      <div class="main">
        <div class="flex-container">
          <article id="post">

  
    <div class="post-head">
    <div class="post-info">
        <div class="tag-list">
            
                
                    <span class="post-tag">
                        <a href="/tags/ML/">
                            ML
                        </a>
                    </span>    
                           
            
        </div>
        <div class="post-title">
            
            
                Debugging Gradient Checking
            
            
        </div>
        <span class="post-date">
            Aug 13, 2021
        </span>
    </div>
    <div class="post-img">
        
            <div class="h-line-primary"></div>
              
    </div>
</div>
    <div class="post-content">
    <h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在很多机器学习的算法中，在训练模型的时候，我们都会经常使用梯度下降法来对模型中的需要学习的参数进行更新，而梯度下降法就必须要运用到导数的运算了，因此验证自己算出来的导数是否正确十分有必要，不然最后模型效果不理想却又不知道具体的原因就不好了</p>
<p><img src="https://i.loli.net/2021/08/13/l7Ttik9xOGbDRPH.png"></p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>回忆一下导数的数学推导, 假设$J:R\to R,\theta\in R$<br>$$<br>\frac{dJ{(\theta)}}{d\theta}=\lim\limits_{\epsilon\to0}\frac{J(\theta+\epsilon)-J(\theta-\epsilon)}{2\epsilon}<br>$$<br>因此，给定一个点$\theta$，我们可以用上面的式子去接近导数的值</p>
<p>在实际应用中，通常可以取$\epsilon$为一个很小的值$10^{-4}$</p>
<p>然后还需要考虑的是$\theta$的取值。在实际应用中，一般$J:R^n\to R,\theta\in R^n$</p>
<p>通常可以对每一个维度都进行上面的操作<br>$$<br>g_i(\theta)=\frac{\partial J(\theta)}{\partial\theta_i}=\frac{J(\theta^{(i+)})-J(\theta^{(i-)})}{2\times EPSILON}<br>$$<br>$\theta^{(i+)}=\theta+ \epsilon e_i$</p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradcheck_naive</span>(<span class="params">f, x, gradientText</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">    Gradient check for a function f.</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    f -- a function that takes a single argument and outputs the</span></span><br><span class="line"><span class="string">         loss and its gradients</span></span><br><span class="line"><span class="string">    x -- the point (numpy array) to check the gradient at</span></span><br><span class="line"><span class="string">    gradientText -- a string detailing some context about the gradient computation</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    rndstate = random.getstate()</span><br><span class="line">    random.setstate(rndstate)</span><br><span class="line">    fx, grad = f(x) <span class="comment"># Evaluate function value at original point</span></span><br><span class="line">    h = <span class="number">1e-4</span>        <span class="comment"># Do not change this!</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Iterate over all indexes ix in x to check the gradient.</span></span><br><span class="line">    it = np.nditer(x, flags=[<span class="string">&#x27;multi_index&#x27;</span>], op_flags=[<span class="string">&#x27;readwrite&#x27;</span>])</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> it.finished:</span><br><span class="line">        ix = it.multi_index</span><br><span class="line"></span><br><span class="line">        x[ix] += h <span class="comment"># increment by h</span></span><br><span class="line">        random.setstate(rndstate)</span><br><span class="line">        fxh, _ = f(x) <span class="comment"># evalute f(x + h)</span></span><br><span class="line">        x[ix] -= <span class="number">2</span> * h <span class="comment"># restore to previous value (very important!)</span></span><br><span class="line">        random.setstate(rndstate)</span><br><span class="line">        fxnh, _ = f(x)</span><br><span class="line">        x[ix] += h</span><br><span class="line">        numgrad = (fxh - fxnh) / <span class="number">2</span> / h</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compare gradients</span></span><br><span class="line">        reldiff = <span class="built_in">abs</span>(numgrad - grad[ix]) / <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">abs</span>(numgrad), <span class="built_in">abs</span>(grad[ix]))</span><br><span class="line">        <span class="keyword">if</span> reldiff &gt; <span class="number">1e-5</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Gradient check failed for %s.&quot;</span> % gradientText)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;First gradient error found at index %s in the vector of gradients&quot;</span> % <span class="built_in">str</span>(ix))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Your gradient: %f \t Numerical gradient: %f&quot;</span> % (</span><br><span class="line">                grad[ix], numgrad))</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        it.iternext() <span class="comment"># Step to next dimension</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Gradient check passed!.&quot;</span>)</span><br></pre></td></tr></table></figure>


</div> 

<script>
    window.onload = detectors();
</script>
    <div class="post-footer">
    <div class="h-line-primary"></div>
    <nav class="post-nav">
        <div class="prev-item">
           
                <div class="icon arrow-left"></div>
                <div class="post-link">
                    <a href="/2021/08/14/%E6%97%A5%E8%AF%AD%E6%9D%82%E5%AD%A6%EF%BC%881%EF%BC%89/">Prev</a>
                </div>
            
        </div>
        <div class="next-item">
            
        </div>
    </nav>
</div>

  
</article>
        </div>
      </div>
      
      <div class="footer">
    <div class="flex-container">
        <div class="footer-text">
            
            
            
                Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> & <a target="_blank" rel="noopener" href="https://hexo.io/">Frame</a>
                
        </div>
    </div>
</div>

    </div>

  </body>
</html>
